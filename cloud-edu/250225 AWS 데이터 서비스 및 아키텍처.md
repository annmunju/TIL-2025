https://explore.skillbuilder.aws/learn/courses/21899/data-engineering-on-aws-foundations-hangug-eo/lessons/159288/foundations-tools-and-considerations

- 데이터 엔지니어와 협력할 수 있는 사용자

| **페르소나**                    | **책임**                                                                             | **관심 영역**                                                                        |
| --------------------------- | ---------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- |
| **Chief Data Officer(CDO)** | 데이터를 사용하여 문제를 해결하고 혁신을 가속화하는 문화를 구축합니다.                                            | 데이터 품질, 데이터 거버넌스, 데이터 및 인공 지능(AI) 전략, 비즈니스에 대한 데이터 가치 전파                         |
| **Data architect**          | 비즈니스 요구 사항을 충족하는 기술 솔루션을 설계하는 데 주력하고, CDO가 비전을 실현할 수 있도록 복잡한 데이터 과제를 해결하는 데 집중합니다. | 데이터 파이프라인, 데이터 처리, 데이터 통합, 데이터 거버넌스, 데이터 카탈로그                                    |
| **Data engineer**           | 사용 가능하고 정확한 데이터세트를 안전하고 성능이 뛰어난 방식으로 조직에 전달합니다.                                    | 데이터 파이프라인 구축, 사용 편의성, 구성, 유지 보수에 사용되는 다양한 도구                                     |
| **Data security officer**   | 데이터 보안, 개인 정보 보호, 거버넌스가 엄격하게 정의되고 준수되도록 보장합니다.                                     | 정보 보안 유지, 데이터 프라이버시 규정 준수, 개인 식별 정보(PII) 보호, 세분화된 액세스 제어 및 데이터 마스킹 적용            |
| **Data scientist**          | 기업에서 더 나은 결정을 내릴 수 있도록 데이터에서 비즈니스 중심 인사이트를 빠르게 추출하는 수단을 구축합니다.                     | 데이터 조작을 간소화하고, 기계 학습(ML) 파이프라인을 구축하는 데 도움이 되는 시각화 도구 및 도구보다 더 심층적인 인사이트를 제공하는 도구 |
| **Data analyst**            | 실시간으로 시장 상황에 대응하고, 데이터를 찾고 빠르고 쉽게 분석할 수 있어야 합니다.                                   | 데이터를 쿼리하고 분석을 수행하여 새 비즈니스 인사이트를 생성하고 비즈니스 인사이트를 설명하는 보고서 및 시각화 생성                |

- 데이터 엔지니어가 데이터를 검색하는 단계
	- 비즈니스 가치 정의
	- 데이터 소비자 식별
	- 데이터 소스 식별
	- 스토리지, 카탈로그 및 데이터 액세스 요구사항 정의
	- 데이터 처리 요구사항 정의
- 데이터 아키텍처 기본 워크플로
	- 수집
	- 저장
	- 카탈로그화
	- 처리
	- 전달
	- 보안 및 거버넌스

### 저장
- S3

### 수집
- AWS DMS : 관계형 및 비관계형 데이터베이스에서 데이터를 로드
- Firehose : 데이터 스트림 수집. Parquet 또는 ORC 같은 형식으로 변환하거나 데이터 압축 해제, 사용자 지정 데이터 변환 수행
- AWS MSK (managed streaming for kafka): 실시간 스트리밍 데이터 파이프라인 및 애플리케이션을 위한 카프카 클러스터 구축
- AWS IoT Core
- AWS DataSync : 온프렘 파일 공유, 객체 스토리지 시스템, 하둡 클러스터에서 AWS 스토리지 서비스로 전송. 예약 일정에 따라 동기화
- Transfer Family : SFTP, FTPS 프로토콜을 통해 S3 송수신 파일 전송 자동화
- AWS Snowball : 물리적 디바이스로 전송

### 카탈로그화
- AWS Glue 데이터 카탈로그 : 데이터 레이크 콘텐츠에 대한 단일 정보 소스를 제공하도록 설계

### 처리
- AWS Glue: ETL 
- EMR : 오픈소스 프레임워크, EC2, 클러스터, EKS, EMR 등을 통해 빅데이터 세트 처리. (배치 작업)
- Flink : 실시간 데이터 처리를 위한 SQL 코드 빠르게 작성

### 전달
- Redshift : 데이터 이동 없이 여러 데이터 베이스와 대규모 정형 데이터 세트 직접 분석 가능
- Athena : S3 에서 SQL로 조회
- EMR : 로그분석 기계학습, DS, 웹 인덱싱 등 수행 가능
- DB
- OpenSearch : 클러스터 배포 운영 및 규모 조정
- QuickSight : SQL, 차트, 그래프. 대시보드를 통해 데이터 세트 시각화 및 분석
- SageMaker: 예측, CV, LM, Recommend system 등에 활용할 ML 모델 구축 훈련 및 배포

### 보안 및 거버넌스
- 보안 : 무단 액세스, 위반 또는 공격으로부터 데이터 보호하기 위한 조치
- 거버넌스 : 데이터 적절 관리, 품질 및 사용 보장 정책, 절차, 프로세스. 

- AWS Lake Formation: 데이터 엑세스 권한 중앙관리
- IAM
- KMS
- Macie : PII 같은 민감 데이터 검색, 분류, 보호
- DataZone : 데이터 카탈로그화, 검색, 공유 및 관리
- Audit Manager : 사용량 감사하여 위험, 규정 준수, 산업 표준 준수 평가


### 용어
- 데이터 사일로 : 부서 또는 개별 사용 사례에 최적화된 격리되고 호환되지 않는 데이터 스토어.